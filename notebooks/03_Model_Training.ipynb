{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed124778-5734-4bd5-83cc-f199a6ed5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2400, 65)\n",
      "Test shape : (600, 65)\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Results → Accuracy: 0.5883, Macro F1: 0.4594, Macro Recall: 0.4870\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6396    0.8325    0.7234       388\n",
      "           1     0.3158    0.1415    0.1954       212\n",
      "\n",
      "    accuracy                         0.5883       600\n",
      "   macro avg     0.4777    0.4870    0.4594       600\n",
      "weighted avg     0.5252    0.5883    0.5369       600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[323  65]\n",
      " [182  30]]\n",
      "\n",
      "Training ExtraTrees...\n",
      "ExtraTrees Results → Accuracy: 0.5467, Macro F1: 0.4763, Macro Recall: 0.4805\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6343    0.7062    0.6683       388\n",
      "           1     0.3214    0.2547    0.2842       212\n",
      "\n",
      "    accuracy                         0.5467       600\n",
      "   macro avg     0.4778    0.4805    0.4763       600\n",
      "weighted avg     0.5237    0.5467    0.5326       600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[274 114]\n",
      " [158  54]]\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Results → Accuracy: 0.5983, Macro F1: 0.4482, Macro Recall: 0.4872\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6400    0.8660    0.7360       388\n",
      "           1     0.3067    0.1085    0.1603       212\n",
      "\n",
      "    accuracy                         0.5983       600\n",
      "   macro avg     0.4733    0.4872    0.4482       600\n",
      "weighted avg     0.5222    0.5983    0.5326       600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[336  52]\n",
      " [189  23]]\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 847, number of negative: 1553\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 454\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 65\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "LightGBM Results → Accuracy: 0.5183, Macro F1: 0.4627, Macro Recall: 0.4639\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6222    0.6495    0.6356       388\n",
      "           1     0.3026    0.2783    0.2899       212\n",
      "\n",
      "    accuracy                         0.5183       600\n",
      "   macro avg     0.4624    0.4639    0.4627       600\n",
      "weighted avg     0.5093    0.5183    0.5134       600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[252 136]\n",
      " [153  59]]\n",
      "\n",
      "Training CatBoost...\n",
      "CatBoost Results → Accuracy: 0.6133, Macro F1: 0.4207, Macro Recall: 0.4860\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6398    0.9201    0.7548       388\n",
      "           1     0.2619    0.0519    0.0866       212\n",
      "\n",
      "    accuracy                         0.6133       600\n",
      "   macro avg     0.4508    0.4860    0.4207       600\n",
      "weighted avg     0.5063    0.6133    0.5187       600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[357  31]\n",
      " [201  11]]\n",
      "\n",
      "✅ Step 3 (Binary) completed successfully!\n",
      "Results saved at: C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML_Final_Project\\data\\processed\\model_results_step3_binary.csv\n",
      "Models saved at: C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML_Final_Project\\models\n"
     ]
    }
   ],
   "source": [
    "# Step3_model_training_binary_fixed.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# ---------------------------\n",
    "# Suppress warnings\n",
    "# ---------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------\n",
    "# ML Imports\n",
    "# ---------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ---------------------------\n",
    "# Base directory (updated)\n",
    "# ---------------------------\n",
    "BASE_DIR = r\"C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML_Final_Project\"\n",
    "\n",
    "# ---------------------------\n",
    "# Paths\n",
    "# ---------------------------\n",
    "PROCESSED_PATH = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Load processed datasets\n",
    "# ---------------------------\n",
    "X_train = np.load(os.path.join(PROCESSED_PATH, \"X_train_binary.npy\"))\n",
    "X_test  = np.load(os.path.join(PROCESSED_PATH, \"X_test_binary.npy\"))\n",
    "y_train = np.load(os.path.join(PROCESSED_PATH, \"y_train_binary.npy\"), allow_pickle=True)\n",
    "y_test  = np.load(os.path.join(PROCESSED_PATH, \"y_test_binary.npy\"), allow_pickle=True)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# Define binary classifiers\n",
    "# ---------------------------\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=500, random_state=42, class_weight=\"balanced\", n_jobs=-1\n",
    "    ),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=500, random_state=42, class_weight=\"balanced\", n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.03,\n",
    "        use_label_encoder=False, eval_metric='logloss', random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.03, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        iterations=500, depth=6, learning_rate=0.03, loss_function=\"Logloss\",\n",
    "        verbose=0, random_seed=42\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# ---------------------------\n",
    "# Train & evaluate models\n",
    "# ---------------------------\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    macro_recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"{name} Results → Accuracy: {acc:.4f}, Macro F1: {macro_f1:.4f}, Macro Recall: {macro_recall:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    results.append({\"Model\": name, \"Accuracy\": acc, \"Macro_F1\": macro_f1, \"Macro_Recall\": macro_recall})\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(MODEL_PATH, f\"{name}_binary_classifier.joblib\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Save results summary\n",
    "# ---------------------------\n",
    "results_df = pd.DataFrame(results).sort_values(\"Macro_F1\", ascending=False)\n",
    "results_file = os.path.join(PROCESSED_PATH, \"model_results_step3_binary.csv\")\n",
    "results_df.to_csv(results_file, index=False)\n",
    "\n",
    "print(\"\\n✅ Step 3 (Binary) completed successfully!\")\n",
    "print(\"Results saved at:\", results_file)\n",
    "print(\"Models saved at:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac3e6a-726a-46e4-b6d3-2c24cb178472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
